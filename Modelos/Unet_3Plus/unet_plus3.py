# -*- coding: utf-8 -*-
"""Copia de Unet+3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YB37uKp6M4yGsZ-g26ki-yRD_a0jAWSs
"""

import numpy as np
from glob import glob
import os
import argparse

from tensorflow import keras
from tensorflow.keras.layers import Input, Conv2D, Dropout, Activation, UpSampling2D, GlobalMaxPooling2D, multiply
from tensorflow.keras.backend import max
import tensorflow as tf

import matplotlib.pyplot as plt

from keras_unet_collection import models, base, utils

import yaml

def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument(
     '--config_file', help='path of config file.', required=True)
    args = parser.parse_args()
    
    # Load the config file
    with open( args.config_file , "r") as ymlfile:
       config_file = yaml.load(ymlfile, Loader=yaml.Loader)
    
    filepath = config_file["DATASET"]["DATA_DIR"]
    NUM_TRAIN_IMAGES= config_file["DATASET"]["NUM_TRAIN_IMAGES"]
    NUM_TEST_IMAGES = config_file["DATASET"]["NUM_TEST_IMAGES"]
    BATCHES_EPOCH= config_file["TRAIN"]["BATCHES_PER_EPOCH"]
    FREEZE_BACKBONE = config_file["MODEL"]["FREEZE_BACKBONE"]
    
    name = 'unet3plus'
    activation = config_file["MODEL"]["ACTIVATION"]
    filter_num_down = [32, 64, 128, 256, 512]
    filter_num_skip = [64, 64, 64, 64] # Within the upsampling block, each input tensor is processed by a convolutional layer with 32 filters ( filter_num_skip=32 )
    filter_num_aggregate = 160 # then concatenated, and passed through another convolutional layer with 160 filters ( filter_num_aggregate=160 )
    
    stack_num_down = 2 # number of convolutional layers per downsampling level.
    stack_num_up = 1 # number of convolutional layers (after concatenation) per upsampling level.
    n_labels = config_file["DATASET"]["NUM_CLASSES"]
    
    # `unet_3plus_2d_base` accepts an input tensor
    # and produces output tensors from different upsampling levels
    # ---------------------------------------- #
    input_tensor = keras.layers.Input((224, 224, 3))
    # base architecture
    X_decoder = base.unet_3plus_2d_base(
        input_tensor, filter_num_down, filter_num_skip, filter_num_aggregate,
        stack_num_down=stack_num_down, stack_num_up=stack_num_up, activation=activation,
        batch_norm=True, pool=True, unpool=True, backbone=config_file["MODEL"]["NET_BACKBONE"], weights='imagenet',
                               freeze_backbone=FREEZE_BACKBONE, freeze_batch_norm=True, name=name)
    
    # allocating deep supervision tensors
    OUT_stack = []
    # reverse indexing `X_decoder`, so smaller tensors have larger list indices. Thus, new order is (224,224,160) --> (14,14,512)
    X_decoder = X_decoder[::-1]
    
    # deep supervision outputs. We take only the second until the last layer.
    for i in range(1, len(X_decoder)):
        # 3-by-3 conv2d --> upsampling --> sigmoid output activation
        pool_size = 2**(i)
        X = Conv2D(n_labels, 3, padding='same', name='{}_output_conv1_{}'.format(name, i-1))(X_decoder[i])
    
        X = UpSampling2D((pool_size, pool_size), interpolation='bilinear',
                         name='{}_output_sup{}'.format(name, i-1))(X)
    
        X = Activation('sigmoid', name='{}_output_sup{}_activation'.format(name, i-1))(X)
        # collecting deep supervision tensors
        OUT_stack.append(X)
    
    # the final output (without extra upsampling) because its dimension is (224,224,160), it doesn't neet to do upsampling
    # 3-by-3 conv2d --> sigmoid output activation
    X = Conv2D(n_labels, 3, padding='same', name='{}_output_final'.format(name))(X_decoder[0])
    X = Activation('sigmoid', name='{}_output_final_activation'.format(name))(X)
    # collecting final output tensors
    OUT_stack.append(X)
    
    # Classification-guided Module (CGM)
    # ---------------------------------------- #
    # dropout --> 1-by-1 conv2d --> global-maxpooling --> sigmoid
    X_CGM = X_decoder[-1]   # it corresponds to (14,14,512)
    X_CGM = Dropout(rate=0.1)(X_CGM)
    X_CGM = Conv2D(filter_num_skip[-1], 1, padding='same')(X_CGM) # output dimension (14,14,32)
    X_CGM = GlobalMaxPooling2D()(X_CGM)
    X_CGM = Activation('sigmoid')(X_CGM)
    
    CGM_mask = max(X_CGM, axis=-1) # <----- This value could be trained with "none-organ image"
    
    for i in range(len(OUT_stack)):
        if i < len(OUT_stack)-1:
            # deep-supervision
            OUT_stack[i] = multiply([OUT_stack[i], CGM_mask], name='{}_output_sup{}_CGM'.format(name, i))
        else:
            # final output
            OUT_stack[i] = multiply([OUT_stack[i], CGM_mask], name='{}_output_final_CGM'.format(name))
    
    # executing all the above cells in one time to avoid dupilcated tensor names.
    unet3plus = keras.models.Model([input_tensor,], OUT_stack)
    
    from keras_unet_collection import losses
    
    def hybrid_loss(y_true, y_pred):
    
        loss_cat_crossE = keras.losses.categorical_crossentropy(y_true, y_pred)
        loss_dice = losses.dice(y_true, y_pred)
        loss_focal = losses.focal_tversky(y_true, y_pred, alpha=0.5, gamma=4/3)
    
    
    
        return  loss_cat_crossE + loss_dice + loss_focal
    
    initial_learning_rate = config_file["TRAIN"]["LEARNING_RATE"]
    decay_steps = 600
    decay_rate = 0.94
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    
    unet3plus.compile(loss=[hybrid_loss, hybrid_loss, hybrid_loss, hybrid_loss, hybrid_loss],
                      loss_weights=[0.25, 0.25, 0.25, 0.25, 1.0],
                      optimizer=keras.optimizers.Adam(learning_rate= lr_schedule))
    
    # loss_weights parameter on compile is used to define how much each of your model output loss contributes to the final loss value.  The loss value that will be minimized by the model will then be the weighted sum of all individual losses.
    # In this case, we have a model with five outputs where one is the primary and the other is the auxiliary,
    # then it is 25%*auxiliary + 25%*auxiliary + 25%*auxiliary + 25%*auxiliary + 100%*primary
    
    def input_data_process(input_array):
        '''converting pixel vales to [0, 1]'''
        return input_array/255.
    
    def target_data_process(target_array):
        '''Converting tri-mask of {1, 2, 3} to three categories.'''
        return keras.utils.to_categorical(target_array-1,num_classes=n_labels)
    
    train_images = np.array(sorted(glob(os.path.join(filepath, "train_img/*"))))[:NUM_TRAIN_IMAGES]
    train_masks = np.array(sorted(glob(os.path.join(filepath, "train_mask_ids/*"))))[:NUM_TRAIN_IMAGES]
    
    val_images = np.array(sorted(glob(os.path.join(filepath, "test_img/*"))))[:NUM_TEST_IMAGES]
    val_masks = np.array(sorted(glob(os.path.join(filepath, "test_mask_ids/*"))))[:NUM_TEST_IMAGES]
    
    L = len(train_images)
    ind_all = utils.shuffle_ind(L) # create a list with random number from 0 until L (without repeat)
    
    L_1 = len(val_images)
    ind_all_1 = utils.shuffle_ind(L_1) # create a list with random number from 0 until L (without repeat)
    
    L_train = L ; L_valid = L_1; L_test = L_1
    ind_train = ind_all; ind_valid = ind_all_1; ind_test = ind_all_1
    
    valid_input = input_data_process(utils.image_to_array(val_images[ind_valid], size=224, channel=3))
    valid_target = target_data_process(utils.image_to_array(val_masks[ind_valid], size=224, channel=1))
    
    test_input = input_data_process(utils.image_to_array(val_images[ind_valid], size=224, channel=3))
    test_target = target_data_process(utils.image_to_array(val_masks[ind_valid], size=224, channel=1))
    
    N_epoch = config_file["TRAIN"]["NUM_EPOCHES"] # number of epoches
    N_batch = BATCHES_EPOCH # number of batches per epoch
    N_sample = config_file["TRAIN"]["SAMPLES_PER_BATCH"] # number of samples per batch
    
    tol = 0 # current early stopping patience
    max_tol = config_file["TRAIN"]["EARLY_STOPPING"] # the max-allowed early stopping patience
    min_del = 0 # the lowest acceptable loss value reduction
    
    # loop over epoches
    for epoch in range(N_epoch):
    
        # initial loss record
        if epoch == 0:
            temp_out = unet3plus.predict([valid_input])
            y_pred = temp_out[-1]
            record = np.mean(hybrid_loss(valid_target, y_pred))
            print('\tInitial loss = {}'.format(record))
    
        # loop over batches
        for step in range(N_batch):
            # selecting samples for the current batch
            ind_train_shuffle = utils.shuffle_ind(L_train)[:N_sample]
    
            # batch data formation
            ## augmentation is NOT applied
            train_input = input_data_process(
                utils.image_to_array(train_images[ind_train][ind_train_shuffle], size=224, channel=3))
            train_target = target_data_process(utils.image_to_array(train_masks[ind_train][ind_train_shuffle], size=224, channel=1))
    
            # train on batch
            loss_ = unet3plus.train_on_batch([train_input,],
                                             [train_target, train_target, train_target, train_target, train_target,])
    
        # epoch-end validation
        temp_out = unet3plus.predict([valid_input])
        y_pred = temp_out[-1]
        record_temp = np.mean(hybrid_loss(valid_target, y_pred))
        # ** validation loss is not stored ** #
    
        # if loss is reduced
        if record - record_temp > min_del:
            print('Validation performance is improved from {} to {}'.format(record, record_temp))
            record = record_temp; # update the loss record
            tol = 0; # refresh early stopping patience
            # ** model checkpoint is not stored ** #
    
        # if loss not reduced
        else:
            print('Validation performance {} is NOT improved'.format(record_temp))
            tol += 1
            if tol >= max_tol:
                print('Early stopping')
                break;
            else:
                # Pass to the next epoch
                continue;
    
    unet3plus.save(config_file["MODEL"]["SAVE_MODEL"])
    
    temp_out = unet3plus.predict([test_input,])
    y_pred = temp_out[-1]  # shape (79, 224, 224, 4)
    
    print('Testing set cross-entropy loss = {}'.format(np.mean(keras.losses.categorical_crossentropy(test_target, y_pred))))
    print('Testing set focal Tversky loss = {}'.format(np.mean(losses.focal_tversky(test_target, y_pred))))
    print('Testing set IoU loss = {}'.format(np.mean(losses.iou_seg(test_target, y_pred))))
    
    def compute_metrics(y_true, y_pred):
    
      class_wise_iou = []
      class_wise_dice_score = []
      list_labels_id = []
    
      smoothening_factor = 0.00001
    
      list_id= list(np.unique(y_true))
      dicc_id= {3:'Fondo',0:'Agua', 1:'Cianobacterias', 2:'Rocas'}
    
    
      for i in list_id:
        intersection = np.sum((y_pred == i) * (y_true == i))
        y_true_area = np.sum((y_true == i))
        y_pred_area = np.sum((y_pred == i))
        combined_area = y_true_area + y_pred_area
    
        iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)
        class_wise_iou.append(iou)
    
        dice_score =  (2 *(intersection + smoothening_factor) / (combined_area + smoothening_factor))
        class_wise_dice_score.append(dice_score)
        list_labels_id.append(dicc_id[i])
    
      return class_wise_iou, class_wise_dice_score, list_labels_id
    
    colormap = np.array([[0,0,0],[255,50,50],[214,255,50],[50,255,132]])
    colormap = colormap.astype(np.uint8)
    
    
    def infer(predictions): # input is a predictions with shape (224,224,4)
        predictions = np.argmax(predictions, axis=2) # the inverse of to_categorical is np.argmax
        return predictions
    
    
    def decode_segmentation_masks(mask, colormap, n_classes):
        r = np.zeros_like(mask).astype(np.uint8)
        g = np.zeros_like(mask).astype(np.uint8)
        b = np.zeros_like(mask).astype(np.uint8)
        for l in range(0, n_classes):
            idx = mask == l
            r[idx] = colormap[l, 0]
            g[idx] = colormap[l, 1]
            b[idx] = colormap[l, 2]
        rgb = np.stack([r, g, b], axis=2)
        return rgb
    
    def plot_samples_matplotlib(display_list, display_string, figsize=(5, 3)):
        fig, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)
        title = ['Input Image','Predicted Mask', 'True Mask']
        for i in range(len(display_list)):
    
            if display_list[i].shape[-1] == 3:
                axes[i].title.set_text(title[i])
    
                axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))
    
            else:
                axes[i].imshow(display_list[i])
    
        fig.text(0.5, 0.3,display_string, horizontalalignment='center',
         verticalalignment='bottom')
        #plt.show()
        plt.savefig("./pred_vs_ground_img.png")
    
    
    def plot_predictions(index, colormap):
        image_tensor = test_input[index]
        ground_truth_tensor = test_target[index]
        prediction_mask = infer(y_pred[index])
        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 4)
        ground_truth_mask =  np.argmax(ground_truth_tensor,axis=2).astype(np.uint8)
        ground_truth_colormap = decode_segmentation_masks(ground_truth_mask, colormap, 4)
    
        iou_list, dice_score_list, labels_id = compute_metrics(ground_truth_mask,prediction_mask)
        metrics_by_id = [(idx, iou, dice_score) for i, (idx,iou, dice_score) in enumerate(zip(iou_list, dice_score_list, labels_id)) if iou > 0.0]
        display_string_list = ["{}: IOU: {} Dice Score: {}".format(idx, iou, dice_score) for iou, dice_score, idx in metrics_by_id]
        display_string = "\n\n".join(display_string_list)
        plot_samples_matplotlib(
            [image_tensor, prediction_colormap,ground_truth_colormap], display_string, figsize=(18, 14)
        )
    
    plot_predictions(0,colormap)
    
if __name__ == '__main__':
  main()