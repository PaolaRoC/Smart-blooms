# -*- coding: utf-8 -*-
"""Copia de Deeplabv3plus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1goXzT1M_k6dZfWdJA7NKQreQ4XzOXEPo

#Cargar librerias
"""

import os
import argparse


from glob import glob

import cv2

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers


import numpy as np

import matplotlib.pyplot as plt

import yaml

seed=42
IMAGE_SIZE = 224

def read_image(image_path, mask=False):
    image = tf.io.read_file(image_path)

    if mask:
        image = tf.image.decode_png(image, channels=1)
        image.set_shape([None, None, 1])
        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])
    else:
        image = tf.image.decode_png(image, channels=3)
        image.set_shape([None, None, 3])
        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])
        image = tf.keras.applications.resnet50.preprocess_input(image)
    return image


def load_data(image_list, mask_list):
    image = read_image(image_list)
    mask = read_image(mask_list, mask=True)
    return image, mask


def data_generator(image_list, mask_list):

    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))
    dataset = dataset.map(load_data,num_parallel_calls=tf.data.AUTOTUNE)
    return dataset


"""# Aumentar los datos"""

class Augment(tf.keras.layers.Layer):
    def __init__(self, seed=42):
        super().__init__()

        self.augment_inputs = [
            tf.keras.layers.RandomFlip(mode="horizontal", seed=seed),
            tf.keras.layers.RandomRotation(factor=0.25, fill_mode="wrap", seed=seed),
            tf.keras.layers.RandomTranslation(height_factor=0.25, width_factor=0.25, fill_mode="wrap", seed=seed),
            tf.keras.layers.RandomZoom(height_factor=(-0.3, -0.2), fill_mode="wrap", seed=seed)
        ]

        self.augment_labels = [
            tf.keras.layers.RandomFlip(mode="horizontal", seed=seed),
            tf.keras.layers.RandomRotation(factor=0.25, fill_mode="wrap", seed=seed),
            tf.keras.layers.RandomTranslation(height_factor=0.25, width_factor=0.25, fill_mode="wrap", seed=seed),
            tf.keras.layers.RandomZoom(height_factor=(-0.3, -0.2), fill_mode="wrap", seed=seed)
        ]

    def call(self, inputs, labels):
        augmented_inputs = [inputs]
        augmented_labels = [labels]

        for augment_input in self.augment_inputs:
            augmented_inputs.append(augment_input(inputs))

        for augment_label in self.augment_labels:
            augmented_labels.append(augment_label(labels))

        augmented_inputs = tf.stack(augmented_inputs)
        augmented_labels = tf.stack(augmented_labels)

        return augmented_inputs, augmented_labels



"""# Construir el modelo"""

def convolution_block(
    block_input,
    num_filters=256,
    kernel_size=3,
    dilation_rate=1,
    padding="same",
    use_bias=False,
):
    x = layers.Conv2D(
        num_filters,
        kernel_size=kernel_size,
        dilation_rate=dilation_rate,
        padding="same",
        use_bias=use_bias,
        kernel_initializer=keras.initializers.HeNormal(),
    )(block_input)
    x = layers.BatchNormalization()(x)
    return tf.nn.relu6(x)


def DilatedSpatialPyramidPooling(dspp_input):
    dims = dspp_input.shape
    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)
    x = convolution_block(x, kernel_size=1, use_bias=True)
    out_pool = layers.UpSampling2D(
        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation="bilinear",
    )(x)

    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)
    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)
    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)
    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)

    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])
    output = convolution_block(x, kernel_size=1)
    return output

def DeeplabV3Plus(image_size, num_classes, network_backbone):
    model_input = keras.Input(shape=(image_size, image_size, 3))

    if network_backbone == "ResNet50v02":
      backbone = tf.keras.applications.resnet_v2.ResNet50V2(
          weights="imagenet", include_top=False, input_tensor=model_input)
      layer_a= "conv2_block3_1_relu"
      layer_b= "conv4_block6_1_relu"
      factor= 4
    if network_backbone == "Xception":
      backbone = tf.keras.applications.xception.Xception(
          weights="imagenet", include_top=False, input_tensor=model_input)
      layer_a= "block4_sepconv2_act"
      layer_b= "block14_sepconv1_act"
      factor= 8
    if network_backbone == "MobilNetLarge":
      backbone = tf.keras.applications.MobileNetV3Large(
          weights="imagenet", include_top=False, input_tensor=model_input)
      layer_a= "re_lu_9"
      layer_b= "re_lu_36"
      factor= 8
    if network_backbone == "EfficientNetV2S":
      backbone = tf.keras.applications.efficientnet_v2.EfficientNetV2S(
          weights="imagenet", include_top=False, input_tensor=model_input)
      layer_a= "block2d_project_conv"
      layer_b= "block6a_expand_conv"
      factor= 4
    if network_backbone == "DenseNet201":
      backbone = tf.keras.applications.densenet.DenseNet201(
          weights="imagenet", include_top=False, input_tensor=model_input)
      layer_a= "pool2_relu"
      layer_b= "pool4_relu"
      factor= 4
    else:
      print("Elige un backbone: ResNet50v02, Xception, MobilNetLarge, EfficientNetV2S, DenseNet201")

    x = backbone .get_layer(layer_b).output
    x = DilatedSpatialPyramidPooling(x)

    input_a = layers.UpSampling2D(
        size=(image_size // factor // x.shape[1], image_size // factor // x.shape[2]),
        interpolation="bilinear",
    )(x)

    input_b = backbone .get_layer(layer_a).output
    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)

    x = layers.Concatenate(axis=-1)([input_a, input_b])
    x = convolution_block(x)
    x = convolution_block(x)
    x = layers.UpSampling2D(
        size=(image_size // x.shape[1], image_size // x.shape[2]),
        interpolation="bilinear",
    )(x)
    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding="same")(x)
    return keras.Model(inputs=model_input, outputs=model_output)



"""# Métricas evaluación"""

def compute_metrics(y_true, y_pred):

  class_wise_iou = []
  class_wise_dice_score = []
  list_labels_id = []

  smoothening_factor = 0.00001

  list_id= list(np.unique(y_true))
  dicc_id= {0:'Fondo',1:'Agua', 2:'Cianobacterias', 3:'Rocas'}


  for i in list_id:
    intersection = np.sum((y_pred == i) * (y_true == i))
    y_true_area = np.sum((y_true == i))
    y_pred_area = np.sum((y_pred == i))
    combined_area = y_true_area + y_pred_area

    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)
    class_wise_iou.append(iou)

    dice_score =  (2 *(intersection + smoothening_factor) / (combined_area + smoothening_factor))
    class_wise_dice_score.append(dice_score)
    list_labels_id.append(dicc_id[i])

  return class_wise_iou, class_wise_dice_score, list_labels_id

"""Visualización: predicción vs ground truth"""

colormap = np.array([[0,0,0],[255,50,50],[214,255,50],[50,255,132]])
colormap = colormap.astype(np.uint8)


def infer(model, image_tensor):
    predictions = model.predict(np.expand_dims((image_tensor), axis=0))
    predictions = np.squeeze(predictions)
    predictions = np.argmax(predictions, axis=2)
    return predictions


def decode_segmentation_masks(mask, colormap, n_classes):
    r = np.zeros_like(mask).astype(np.uint8)
    g = np.zeros_like(mask).astype(np.uint8)
    b = np.zeros_like(mask).astype(np.uint8)
    for l in range(0, n_classes):
        idx = mask == l
        r[idx] = colormap[l, 0]
        g[idx] = colormap[l, 1]
        b[idx] = colormap[l, 2]
    rgb = np.stack([r, g, b], axis=2)
    return rgb


def get_overlay(image, colored_mask):
    image = tf.keras.preprocessing.image.array_to_img(image)
    image = np.array(image).astype(np.uint8)
    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)
    return overlay


def plot_samples_matplotlib(display_list, display_string, figsize=(5, 4)):
    fig, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)
    title = ['Input Image', 'Predicted Mask + Input Image ','Predicted Mask', 'True Mask']
    for i in range(len(display_list)):

        if display_list[i].shape[-1] == 3:
            axes[i].title.set_text(title[i])

            axes[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))

        else:
            axes[i].imshow(display_list[i])

    fig.text(0.5, 0.3,display_string, horizontalalignment='center',
     verticalalignment='bottom')
    plt.show()
    plt.savefig("./pred_vs_ground_img.png")


def plot_predictions(images_list, ground_truth_list, colormap, model):
    for image_file, ground_truth_file in zip(images_list, ground_truth_list):
        image_tensor = read_image(image_file)
        ground_truth_tensor = read_image(ground_truth_file, mask=True)
        prediction_mask = infer(image_tensor=image_tensor, model=model)
        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 4)
        ground_truth_mask =  np.squeeze(ground_truth_tensor).astype(np.uint8)
        ground_truth_colormap = decode_segmentation_masks(ground_truth_mask, colormap, 4)
        overlay = get_overlay(image_tensor, prediction_colormap)
        iou_list, dice_score_list, labels_id = compute_metrics(ground_truth_mask,prediction_mask)
        metrics_by_id = [(idx, iou, dice_score) for i, (idx,iou, dice_score) in enumerate(zip(iou_list, dice_score_list, labels_id)) if iou > 0.0]
        display_string_list = ["{}: IOU: {} Dice Score: {}".format(idx, iou, dice_score) for iou, dice_score, idx in metrics_by_id]
        display_string = "\n\n".join(display_string_list)
        plot_samples_matplotlib(
            [image_tensor, overlay, prediction_colormap,ground_truth_colormap], display_string, figsize=(18, 14)
        )



def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument(
     '--config_file', help='path of config file.', required=True)
    args = parser.parse_args()
    
    # Load the config file
    with open( args.config_file , "r") as ymlfile:
       config_file = yaml.load(ymlfile, Loader=yaml.Loader)

    BATCH_SIZE = config_file["TRAIN"]["BATCH_SIZE"]

    NUM_CLASSES = config_file["DATASET"]["NUM_CLASSES"]
    NET_BACKBONE= config_file["MODEL"]["NET_BACKBONE"]

    DATA_DIR= config_file["DATASET"]["DATA_DIR"]
    NUM_TRAIN_IMAGES= config_file["DATASET"]["NUM_TRAIN_IMAGES"]
    NUM_TEST_IMAGES = config_file["DATASET"]["NUM_TEST_IMAGES"]

    """# Generar los datos"""

    train_images = sorted(glob(os.path.join(DATA_DIR, "train_img/*")))[:NUM_TRAIN_IMAGES]
    train_masks = sorted(glob(os.path.join(DATA_DIR, "train_mask_ids/*")))[:NUM_TRAIN_IMAGES]

    val_images = sorted(glob(os.path.join(DATA_DIR, "test_img/*")))[:NUM_TEST_IMAGES]
    val_masks = sorted(glob(os.path.join(DATA_DIR, "test_mask_ids/*")))[:NUM_TEST_IMAGES]
    
    train_dataset = data_generator(train_images, train_masks)
    val_dataset = data_generator(val_images, val_masks)

    print("Train Dataset:", train_dataset)
    print("Val Dataset:", val_dataset)
    
    """# Crear 'batch'"""

    train_batches = (
        train_dataset
        .map(Augment())
        .rebatch(BATCH_SIZE)
        .repeat()
        .prefetch(buffer_size=tf.data.AUTOTUNE)
    )

    test_batches = val_dataset.batch(BATCH_SIZE)
    
    """# Crear el modelo"""
    model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES, network_backbone= NET_BACKBONE)
    
    
    """# Entrenar el modelo"""
    
    VALIDATION_STEPS= NUM_TEST_IMAGES // BATCH_SIZE
    STEPS_PER_EPOCH = (NUM_TRAIN_IMAGES*5) // BATCH_SIZE
    print('VALIDATION_STEPS:', VALIDATION_STEPS)
    print('STEPS_PER_EPOCH:', STEPS_PER_EPOCH)
    
    initial_learning_rate = config_file["TRAIN"]["LEARNING_RATE"]
    num_epochs = config_file["TRAIN"]["NUM_EPOCHS"]
    decay_steps = 10000
    decay_rate = 0.94
    
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    
    early_stop = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss', patience=15)
    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
    optimizer= keras.optimizers.Adam(learning_rate=lr_schedule)
    model.compile(
        optimizer= optimizer,
        loss= loss,
        metrics= [
                  tf.keras.metrics.IoU(num_classes=4, target_class_ids=[1], sparse_y_true = True, sparse_y_pred = False),
                  tf.keras.metrics.IoU(num_classes=4, target_class_ids=[2], sparse_y_true = True, sparse_y_pred = False),
                  tf.keras.metrics.MeanIoU(num_classes=4, sparse_y_true = True, sparse_y_pred = False)],
    )
    
    history = model.fit(train_batches, epochs=num_epochs, steps_per_epoch=STEPS_PER_EPOCH, validation_steps=VALIDATION_STEPS,validation_data=test_batches,
                        callbacks= [early_stop])
    model.save(config_file["MODEL"]["SAVE_MODEL"]) #> acceso a .predict method
    
    """# Gráficas 'Loss' y 'IoU'"""

    plt.plot(history.history["loss"])
    plt.title("Training Loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    #plt.show()
    plt.savefig("./train_loss_img.png")

    plt.plot(history.history["io_u_1"])
    plt.title("Training IoU")
    plt.ylabel("iou")
    plt.xlabel("epoch")
    #plt.show()
    plt.savefig("./train_iou_img.png")

    plt.plot(history.history["val_loss"])
    plt.title("Validation Loss")
    plt.ylabel("val_loss")
    plt.xlabel("epoch")
    #plt.show()
    plt.savefig("./val_loss_img.png")


    plt.plot(history.history["val_io_u_1"])
    plt.title("Validation IoU")
    plt.ylabel("val_iou")
    plt.xlabel("epoch")
    #plt.show()
    plt.savefig("./val_iou_img.png")
    
    """# Gráficas métricas"""
    
    #plot_predictions(train_images[:1], train_masks[:1], colormap, model=model)

    plot_predictions(val_images[:1], val_masks[:1], colormap, model=model)
    
if __name__ == '__main__':
  main()
        
    

    
